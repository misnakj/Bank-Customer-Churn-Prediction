# -*- coding: utf-8 -*-
"""misna_mini_prjct_2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZukpC5xYOv79qu29OltAchfPrT98eVZW

**IMPORTING LIBRARIES**
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

"""**IMPORT DATA**"""

df=pd.read_csv("/content/Churn_Modelling.csv")
df

"""**DATA PRE PROCESSING**"""

df.head()

df.tail()

df.columns

df['Exited'].value_counts()

df.size

df.shape

#ckecking duplicate records
duplicates=df.duplicated()
df[duplicates]

#drop duplicates
df=df.drop_duplicates()

#checking null values
df.isna().sum()

"""**DATA VISUALIZATION**"""

count=sns.countplot(x='Exited',data=df,hue='Exited')

sns.countplot(x='Exited',data=df,hue='Gender')

sns.countplot(x='Exited',data=df,hue='IsActiveMember')

sns.countplot(x='Exited',data=df,hue='Geography')

my_label=['not exited','exited']
plt.pie(df['Exited'].value_counts(),labels=my_label, autopct='%1.1f%%')

sns.countplot(x='Tenure', hue='Exited', data=df)
plt.title('Relationship between Tenure and Churn')
plt.xlabel('Tenure (Years)')
plt.ylabel('Count')
plt.legend(title='Exited', labels=['Not Churned', 'Churned'])

my_label=['not senior citizen','senior citizen']
plt.pie((df['Age']>=60).value_counts(),autopct='%1.1f%%')

df['Age Group'] = df['Age'].apply(lambda x: 'Age >= 60' if x >= 60 else 'Age < 60')
df

import plotly.express as px
fig = px.histogram(df, x="Exited",
                   color="Age Group",
                   barmode="group",
                   )
fig

df.dtypes

"""**ENCODING**"""

dummy=pd.get_dummies(df[["Geography","Gender"]],drop_first=True)
dummy

df1=pd.concat([df,dummy],axis=1)
df1

df1.columns

#droping unwanted columns
df1=df1.drop(['RowNumber','Surname','Geography','Gender'],axis=1)
df1

df1.dtypes

"""**HANDLING MISSING VALUES**"""

df1.isna().sum()

df1.dropna(inplace=True)

df1.isna().sum()

"""**SEPARATING INPUT AND OUTPUT VALUES**"""

x=df1.drop(['Exited'],axis=1)
x

y=df1['Exited']
y

"""**TRAIN TEST SPLIT**"""

from sklearn.model_selection import train_test_split

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.30,random_state=42)

x_train

x_test

y_train

y_test

"""**NORMALIZATION**"""

from sklearn.preprocessing import StandardScaler

scaler=StandardScaler()

scaler.fit(x_train,x_test)

x_train=scaler.transform(x_train)

x_test=scaler.transform(x_test)

"""**MODEL BUILDING (decision tree)**"""

from sklearn.tree import DecisionTreeClassifier

model=DecisionTreeClassifier()

model.fit(x_train,y_train)

y_pred=model.predict(x_test)
y_pred

"""PERFORMANCE EVALUATION"""

from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay,accuracy_score

matrix=confusion_matrix(y_test,y_pred)
cmd=ConfusionMatrixDisplay(matrix)
cmd.plot()

score=accuracy_score(y_test,y_pred)
score

"""**MODEL 2 (LOGISTIC REGRESSION)**"""

from sklearn.linear_model import LogisticRegression

model1=LogisticRegression()

model1.fit(x_train,y_train)

y_pred1=model1.predict(x_test)
y_pred1

"""PERFORMANCE EVALUATION"""

matrix1=confusion_matrix(y_test,y_pred1)
matrix1

cmd=ConfusionMatrixDisplay(matrix1)
cmd.plot()

score1=accuracy_score(y_test,y_pred1)
score1

"""**MODEL 3(svm)**"""

from sklearn.svm import SVC

model2=SVC()

model2.fit(x_train,y_train)

y_pred2=model.predict(x_test)
y_pred2

score2=accuracy_score(y_test,y_pred2)
score2

matrix2=confusion_matrix(y_test,y_pred2)
matrix2

cmd=ConfusionMatrixDisplay(matrix2)
cmd.plot()

"""**MODEL 4 (RANDOM FOREST)**"""

from sklearn.ensemble import RandomForestClassifier

model3=RandomForestClassifier(n_estimators=100)

model3.fit(x_train,y_train)

y_pred3=model3.predict(x_test)
y_pred3

"""PERFORMANCE EVALUATION"""

from sklearn.metrics import accuracy_score,ConfusionMatrixDisplay,confusion_matrix

matrix3=confusion_matrix(y_test,y_pred3)

cmd=ConfusionMatrixDisplay(matrix3)
cmd.plot()

score3=accuracy_score(y_test,y_pred3)
score3